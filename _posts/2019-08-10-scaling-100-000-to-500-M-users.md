---
title: "Scale your system Part 2: From 100 000 to 500 million users"
biblio:
  - 
    title: "Content Delivery Network (CDN) Caching"
    link: "https://aws.amazon.com/caching/cdn/"
  - 
    title: "What Is a CDN and How Does It Work?"
    link: "https://www.sitepoint.com/what-is-a-cdn-and-how-does-it-work/"
  - 
    title: "Where does session save?"
    link: "https://stackoverflow.com/questions/5593359/where-does-session-save"
  - 
    title: "Active-Active for Multi-Regional Resiliency"
    link: "https://medium.com/netflix-techblog/active-active-for-multi-regional-resiliency-c47719f6685b"
  - 
    title: "Distributed Systems in One Lesson by Tim Berglund"
    link: "https://www.youtube.com/watch?v=Y6Ev8GIlbxc&t=3s"
  - 
    title: "Data Partitioning: Vertical Partitioning, Horizontal Partitioning, and Hybrid Partitioning"
    link: "http://cloudgirl.tech/data-partitioning-vertical-horizontal-hybrid-partitioning/"
---


Part 1: [Scale your system Part 1: From 1 to 99 999 users]({% post_url 2019-08-03-scaling-1-to-10-000-users %})
 
We are onto the 2<sup>nd</sup> part. How do we continue scaling from 100 000 users onwards?

## Stage 4: 100 000 active users

Now it might be time for a **CDN** and a **Stateless architecture**.

### What can be gained by using a CDN?

CDNs offer a network of geographically dispersed servers. The more physically closer the servers are to your users, the shorter the latency is. First-generation CDNs served only static resources: images, css, javascript, ..., but currently, the more advanced CDNs can also deliver dynamic content that is unique to the requestor and not cacheable. But these are already very advanced CDNs. A basic CDN still serves only static resources.

![CDN](/assets/scaling-cdn.jpg)

CDNs make sure that when a user connects to a website, the closest and the best performing server will deliver the static resources for this website. With a basic CDN, the website is still served via your load balancer, but all the static resources (images, css, ...) are served from CDNs.

Initially, if a file changed, you needed to explicitly push it to the CDN. Then, something called "origin pulling" became a thing. This meant the refresh of a file became automatic. When a user requested a resource, the CDN looked into its cache and if the resource was outdated or not there, it fetched the resource from the original website.

This means, you could use your CDN, to cache certain pages or Radiodeck, which will continue to be live even if your own servers are down.

Some CDNs specialize in security. Similar to load balancers, CDNs are also one of the first recipients of traffic and can thus detect and DDoS or other attacks and block them. 

### What is stateless architecture? Weren't we stateless already?

At first glance, you might think: "What state? Are we storing any state?". It might not be immediately evident, but there indeed is some state, we are managing outside of a database, it is the session. 

Storing information in the session means that requests share data. A user logs in one request, but her information is then accessible to all subsequent requests. Since the session is not stored in the database, but in a particular web server's files, all requests from the same user must be processed by the same web server.

In our Radiodeck example, this means that our load balancer needs to remember to which server it sent each request. With enough traffic, this can become a bottleneck.

A solution for this is a so-called stateless architecture. We still need the session information, but just like with other website data, we store it in a database. This time, however, it is important that access to the session data is efficient. The data is also not relational nor structured, each session object is completely independent of the others and might be structured completely differently. This makes session storage the perfect candidate for a NoSQL database type. 

The session database can be Memcached or Redis, which we have already talked about or any other type of NoSQL database.

![Stateless architecture](/assets/scaling-stateless.jpg)

## Stage 5: 500 000 active users

It might be time to split up your web servers into different locations around the world. Having several physical locations from where you can provide your Radiodesk's services has the similar advantages as using a CDN, a lowered latency for your users all around the world, but it also adds redundancy to your system. Should one of your locations experience serious issues, then you can simply redirect traffic to a different location. 

Of course, this makes all the existing problems we've talked about much worse. Synchronizing data among all the different locations is ever more challenging. Keeping files up to date, keeping permissions up to date, keeping the session up to date, user history, ... .

## Stage 6: 1 000 000 active users

We've scaled all kinds of aspects of our architecture, but as you see there is basically 1 rule to scaling. Divide, isolate, cut off. Whenever we wanted to scale anything, we isolated it from the rest and defined a very narrow communication protocol between the old part and the cut-off part. This always gave us the ability to then scale both pieces independently from each other. 

A key tool to achieve this Message queueing. 

### Message queues

We have ended up with a lot of separate pieces in our system, which still need to communicate with each other. The goal is to make this communication independent of the services which use it. Thus we define message publishers, message subscribers and queues of messages.

![Messaging](/assets/Scaling-messaging.jpg)

Message queues are again making our system more decoupled, which makes it more scalable. It also gives us the possibility to schedule an action for a slightly later time (when the server deals with all the already scheduled actions) while the app can continue functioning unencumbered. And should an action be splittable, we can simply split it, send it off and rely on the fact that the action's parts will eventually be executed.

## Stage 7: 50 000 000 active users

At 50M users, you DB is surely starting to give up. We are again facing the question: Do we scale up or out. Maybe the answer is both. But what does scale out look like in databases?

### Vertical partioning (not the same as vertical scaling)

This describes the process where the database is split along tables. Some tables go into database A, others into database B. You would separate tables by functionality. All the data you need for 1 sort of operations goes to database A, the rest to dababase B.

### Horizontal partitioning / sharding


To be continued....
