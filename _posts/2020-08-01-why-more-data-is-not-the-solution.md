---
title: "Why more data does not kill bias"
biblio:
- title: "Cathy O'Neil: Weapons of Math Destruction"
  link: "https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction"
- title: "Judea Pearl & Dana Mackenzie: The Book of Why"
  link: ""
- title: ""
  link: "https://www.researchgate.net/publication/31991741_The_pace_of_life"
- title: "Cesare Lombroso: criminality is inherited and someone \"born criminal\" could be identified by physical defects"
  link: "https://en.wikipedia.org/wiki/Cesare_Lombroso"
- title: "Genetic drift: change of the genetic makeup of a population over time due to randomness."
  link: "https://en.wikipedia.org/wiki/Genetic_drift"
---

Simply: correlation is not causation. It might seem as an obvious thing, but the underlying premise of big data is that correlation does equal causation, at least partly. That given enough data, we can figure out the relationships between data points, between seemingly unrelated facts and can use these known facts to correctly guess unknown facts. But the honest truth is that there is no mathematical model, that can turn garbage input into meaningful output. As an industry we have to start taking responsibility for writing graphs, charts, mathematical models, ... that we know will be fed garbage and will thus show garbage, albeit dressed up with an air of enlightenment.

Here is what I mean. Let's say it's the 1850s, you manage workers in a factory making canned vegetables and you notice that some of the new workers get onboarded very quickly while others need a long time before they become fully capable in their job. As an excellent manager you are interested in hiring more of the talented ones and fewer of the slow ones. So you decide to investigate, what makes an unskilled worker learn faster. As you set out to find the hidden identifiers of good workers, you make a series of "very reasonable" assumptions:
- most, if not all, identifiers should be visible to the naked eye.

  You have constant contact with your workers and sure, they are not completely transparent with you, but they do reveal enough that you have developed a gut feeling over the years.
  All of your workers are un-schooled or little-schooled. Surely, the fast-learners will be eager to show they are fast-learners, since this secures them a job. And as for the slow-learners, their lack of education will make them ill adept at hiding their incompetence. And should there be some you will miss-categorize (which is, given your high intelligence and.. let's be honest superiority, very unlikely), you are only worried about hiring slow learners. If the fast learners were not able to prove themselves, that just proves they are not so fast to learn after all. And to prevent the hire of slow learners, it should be sufficient to just raise the bar a bit.

- you will record and measure everything you can on your current and past workers to construct a predictability model.

  You have 1000 workers in the factory, which should be more than enough to capture all the general differences in the population of the fast-workers. And should this not be enough, you will ask other nearby factory managers if you can measure their workers. You research is after all also in their best interest. Together you will then hold the descriptions of 10 000 workers, which is clearly more than enough to be statistically significant.

And now the important bit: what are you going to measure. As a product of your society, you will of course start with the things you have internalized as important on other people and, of course, are easy to measure. So.. let's start with people's faces. The distance between their eyes, the circumference of their head, the length of their neck, the form of their ears, the height of their forehead, the hairiness of their eyebrows, ... that sorts of things.

And so you go ahead, you measure all of your workers and inevitably you come to some conclusions. Because inevitably your 1000 workers do not represent the full spectrum of human faces, they are not of all ages, not of all ethnicity, not of equal representation of both sexes, not of all cultural groups, not of all social groups, ... . Some features will be over- and other under- represented. On top of it, you will soon discover that most people are medium-learners and your decision to put them in the fast- or the slow-learner camp will be part-random. You have thus 2 randomness causing mechanisms in your wannabe-mathematical model: the randomness of who walks into your factory looking for work and the randomness of how you exhausted, angry, satisfied, stressed, hungry, hot, ... you feel the minute you are making sorting decisions.

To remediate this, you can set up rigid rules for determining the speed of learning. If you can give each learner an objective score for their speed, then you have eliminated this second randomness. So you might say: a fast learner is someone, who can do some new task alone in some time frame.  
 who can cook 10l of carrot soup on their 3rd day.



but even if they somehow were (which is completely impossible), there would inevitably be some features, which are over-represented and under-represented in any generation, simply due to the nature of randomly picking a few





In the 19th centuary, we thought we will be able to make better predictions because we could finally measure soo much and we had access to the whole world. In a year you could travel and research all around the world, you could write letters and ask for data, researches would publish their findings form all around the world. It felt like the internet was discovered. So much data was finally available.  


The ability once aquired can never be lost.

Let's say you start noticing that people walk faster in bigger cities than in smaller once, you decide to measure the average walking speed in 15 cities around the world and look and behold, there really are differences: the bigger the city the faster its inhabitants tend to walk.


Statistics is mistical, but it is not as powerful as we are wishing it was.



The problem with statistical data arrises, when a mathematical model is applied to an individual. Statistical analyses were never meant to be applied back onto the population. They were meant to be abstractions, averages of the processes happening in the population. They were meant to show bigger changes or bigger trends. They are not capable to predict any individual's future, because no individual is always an average.


As people we've fallen into this trap a million times before. We are guided by an inner desire to qualify and categorize. Evolutionary it has served us tremendeously to keep simplyfied models of very complicated real-life flows/causes-consequences in our head and to obey them. Every supperstrision on eart is trying to predict the future and most (probably all) of them are not true. But they feel true, to the people who believe in them. In Slovenia some people believe you mustn't congratulate somebody for their birthday before the date, or they might not live long enough to have it. Some people in Philippines ... pagpag. ...

> First, very early in our evolution, we humans realized that the world is not made up of dry facts (what we might call data today); rather, these facts are glued together by an intricate web of cause-effect relationships. Second, causal explanations, not dry facts, make up the bulk of our knowledge, and should be the cornestone of machine learning.


There are several more pitfals to thinking more data will magically rid us of entrenched biases.


But as the rule of entroypy(?) kaos rarely organizes itself into not-kaos by accident.
But understanding of underlying motives, xxx are rarely if ever discovered by accident.

Example: why do people walk faster in big cities in small cities?
Example 2: why are there more people with alergies to polen than 50 years ago?
Example 3: More errors might be just more users.


Unerlying premis:
- there are patterns defining all actions
- we can fidn these patterns
- the more data we have, the more accurate we will be at defining these patterns

Another problem: developers are dumb. Also, they are individual contributors. Great, big, fair systems are rarely constructed by accident. If nobody is leading the way with a benevolent vision, then the end result will probably not be much of a success. But most people will never be selfless enough to make a big angry agressive system work in the interest of the underdogs.
